{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e66d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 6 – Concatenating and Merging\n",
    "\n",
    "## DSC 80, Winter 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadf287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 2 is due **tonight at 11:59PM**.\n",
    "    - You can spend up to one slip day on labs.\n",
    "    - To earn 0.3% of extra credit, you must submit the lab, attend Discussion 2, and submit the Lab 2 Reflection Form by **Saturday at 11:59PM**.\n",
    "- Project 1 is due on **Thursday, January 26th at 11:59PM**.\n",
    "- Lab 1 scores and solutions (for questions not covered in discussion) are posted on Ed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Aside: Time series data.\n",
    "- Concatenating DataFrames vertically and horizontally.\n",
    "- Merging.\n",
    "    - Types of joins.\n",
    "    - Many-to-one and many-to-many joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4029ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aside: Working with time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59e1d02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series – why now?\n",
    "\n",
    "- We're about to start looking at how to combine multiple DataFrames.\n",
    "- Data is often partitioned by time. For instance, there may be one `.csv` file per day for 1 year.\n",
    "- We will need to load in the files as DataFrames and `pd.concat` them together.\n",
    "- Note: \"time series\" is a general term and is not related to Series in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be0709",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Datetime types\n",
    "\n",
    "When working with time data, you will see two different kinds of \"times\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a192faa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Datetimes** reference particular moments in time (e.g. November 26th, 1998 at 8:26AM).\n",
    "    - Could just be a date, e.g. January 23, 2023.\n",
    "    - Could just be a time, e.g. 4:45 AM.\n",
    "    - Datetimes typically don't keep track of timezones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c50fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Timedeltas**, or durations, reference an exact length of time (e.g. a duration of 3 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ea257",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `datetime` module\n",
    "\n",
    "Python has an in-built `datetime` module, which contains `datetime` and `timedelta` types. These are much more convenient to deal with than strings that contain times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a270b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecced75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now() + datetime.timedelta(days=3, hours=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e7e71",
   "metadata": {},
   "source": [
    "Unix timestamps count the number of seconds since January 1st, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165675d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now().timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbed66d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Times in `pandas`\n",
    "\n",
    "- `pd.Timestamp` is the `pandas` equivalent of `datetime`.\n",
    "- `pd.to_datetime` converts strings to `pd.Timestamp` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp(year=1998, month=11, day=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_start = pd.to_datetime('March 22nd, 2023, 11:30AM')\n",
    "final_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish = pd.to_datetime('March 22nd, 2023, 2:30PM')\n",
    "final_finish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7d2e9",
   "metadata": {},
   "source": [
    "Timestamps have time-related attributes, e.g. `dayofweek`, `hour`, `min`, `sec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5754bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0 is Monday, 1 is Tuesday, etc.\n",
    "final_finish.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdaea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68ea42",
   "metadata": {},
   "source": [
    "Subtracting timestamps yields `pd.Timedelta` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_finish - final_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16192b25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Exam speeds\n",
    "\n",
    "Below, we have the Final Exam starting and ending times for two sections of a course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_times = pd.read_csv(os.path.join('data', 'exam-times.csv'))\n",
    "exam_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e71d33",
   "metadata": {},
   "source": [
    "**Question:** Who took the longest time to finish the exam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9024bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert the time columns to timestamps, using pd.to_datetime.\n",
    "exam_times['start_exam'] = pd.to_datetime(exam_times['start_exam'])\n",
    "exam_times['finish_exam'] = pd.to_datetime(exam_times['finish_exam'])\n",
    "exam_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841541a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that datetime64[ns] is the data type pandas uses to store timestamps in a Series/DataFrame.\n",
    "exam_times.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Find the difference between the two time columns.\n",
    "exam_times['difference'] = exam_times['finish_exam'] - exam_times['start_exam']\n",
    "exam_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eefeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_times.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sort by the difference in descending order and take the first row.\n",
    "exam_times.sort_values('difference', ascending=False)['name'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b6b7e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenating vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b52fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the next example.\n",
    "\n",
    "section_A = pd.DataFrame({\n",
    "    'Name': ['Annie', 'Billy', 'Sally', 'Tommy'],\n",
    "    'Midterm': [98, 82, 23, 45],\n",
    "    'Final': [88, 100, 99, 67]\n",
    "})\n",
    "\n",
    "section_B = pd.DataFrame({\n",
    "    'Name': ['Junior', 'Rex', 'Flash'],\n",
    "    'Midterm': [70, 99, 81],\n",
    "    'Final': [42, 25, 90]\n",
    "})\n",
    "\n",
    "section_C = pd.DataFrame({\n",
    "    'Name': ['Justin', 'Marina'],\n",
    "    'Final': [98, 52]\n",
    "})\n",
    "\n",
    "section_D = pd.DataFrame({\n",
    "    'Midterm': [10, 30, 80],\n",
    "    'Name': ['Janine', 'Sooh', 'Suraj']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797631f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades\n",
    "\n",
    "Consider the students from our previous example. Suppose their grades are given to us in separate DataFrames. Note that these DataFrames contain the same attributes, but for different individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53599ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30cf51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question**: How do we combine both DataFrames into a single, larger DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f81e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concatenating vertically\n",
    "\n",
    "<center><img src=\"imgs/merging_append3.png\" width=\"30%\"></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* The `pd.concat` function combines DataFrame and Series objects.\n",
    "* By default, the **rows of objects are stacked on top of one another**.\n",
    "* `pd.concat` has many options; we'll learn some of them here, and you'll discover the others by reading the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a89df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades\n",
    "\n",
    "By default, `pd.concat` takes a list of DataFrames and stacks them row-wise, i.e. on top of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac19ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([section_A, section_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e954904",
   "metadata": {},
   "source": [
    "Setting the optional argument `ignore_index` to `True` fixes the index (which `.reset_index()` also could do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf8409",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([section_A, section_B], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb537deb",
   "metadata": {},
   "source": [
    "To keep track of which original DataFrame each row came from, we can use the `keys` optional argument, though if we do this, the resulting DataFrame has a `MultiIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6378c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([section_A, section_B], keys=['Section A', 'Section B'])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4206d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc['Section A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9856c72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adding a single row\n",
    "\n",
    "To add a single row to a DataFrame, create a new DataFrame that contains the single row, and use `pd.concat`.\n",
    "\n",
    "*The DataFrame `append` method does exist, though it's deprecated.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd508e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row_data = {'Name': 'King Triton', 'Midterm': 21, 'Final': 94}\n",
    "new_row_df = pd.DataFrame([new_row_data]) # Note the list!\n",
    "new_row_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e239fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([section_A, new_row_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaa3985",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing columns?\n",
    "\n",
    "If we concatenate two DataFrames that don't share the same column names, `NaN`s are added in the columns that aren't shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993116e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18148de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that the 'Name' columns were combined, despite not being in the same position!\n",
    "pd.concat([section_C, section_D])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25025e86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ⚠️ Warning: No loops!\n",
    "\n",
    "- `pd.concat` returns a copy; it does not modify any of the input DataFrames.\n",
    "- Do **not** use `pd.concat` in a loop, as it has terrible time and space efficiency.\n",
    "\n",
    "```py\n",
    "total = pd.DataFrame()\n",
    "for df in dataframes:\n",
    "    total = total.concat(df)\n",
    "```\n",
    "\n",
    "- Instead, use `pd.concat(dataframes)`, where `dataframes` is a list of DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f7129",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: Accessing file names programmatically\n",
    "\n",
    "- At times, you'll need to load in all of the files in a given folder.\n",
    "- `os.listdir(dirname)` returns a **list** of the names of the files in the folder `dirname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392cd482",
   "metadata": {},
   "source": [
    "The following does something similar, but in the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317430a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenating horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803118c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the next example.\n",
    "\n",
    "exams = section_A.copy()\n",
    "\n",
    "assignments = exams[['Name']].assign(Homeworks=[99, 45, 23, 81],\n",
    "                                     Labs=[100, 100, 99, 100])\n",
    "\n",
    "overall = pd.DataFrame({\n",
    "    'PID': ['A15253545', 'A10348245', 'A13349069', 'A18485824', 'A10094857'],\n",
    "    'Student': ['Billy', 'Sally', 'Annie', 'Larry', 'Johnny'],\n",
    "    'Final': [88, 64, 91, 45, 89]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefd824",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Grades (again)\n",
    "\n",
    "Suppose we have two DataFrames, `exams` and `assignments`, which both contain different attributes for the same individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b94e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea647b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we try to combine these DataFrames with `pd.concat`, we don't quite get what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f145fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams, assignments])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3f230",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But that's where the `axis` argument becomes handy. \n",
    "\n",
    "Remember, most `pandas` operations default to `axis=0`, but here we want to concatenate the columns of `exams` to the columns of `assignments`, so we should use `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fa95a",
   "metadata": {},
   "source": [
    "Note that the `'Name'` column appears twice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f706a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Concatenating horizontally\n",
    "\n",
    "<center><img src='imgs/merging_concat_series_ignore_index.png' width='50%'></center>\n",
    "\n",
    "- To concatenate two DataFrames horizontally, use `pd.concat` with `axis=1`.\n",
    "- **Concatenation is done by matching indexes, regardless of their order.** It does not look at the information in any of the columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b06d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the call to `pd.concat` below combines information about each individual correctly, even though the orders of the names in `exams_by_name` and `assignments_by_name` are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62279e3f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# .loc[::-1] reverses the rows of the DataFrame.\n",
    "exams_by_name = exams.set_index('Name').iloc[::-1]\n",
    "exams_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035474d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_by_name = assignments.set_index('Name')\n",
    "assignments_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_by_name, assignments_by_name], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03556332",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that `pd.concat` only looks at the index when combining rows, not at any other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams_reversed = exams.iloc[::-1].reset_index(drop=True)\n",
    "exams_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83608817",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([exams_reversed, assignments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2a250",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: `pd.concat`\n",
    "\n",
    "- `pd.concat` \"stitches\" two or more DataFrames together.\n",
    "- If you use `axis=0`, the DataFrames are concatenated **vertically** based on column names (rows on top of rows).\n",
    "- If you use `axis=1`, the DataFrames are concatenated **horizontally** based on row indexes (columns next to columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c62543",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe49a7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Joining\n",
    "\n",
    "- `pd.concat` with `axis=1` combines DataFrames horizontally.\n",
    "- To combine the rows of DataFrames in more advanced ways, we perform a **join** (SQL term), i.e. a **merge** (`pandas` term).\n",
    "- A join is appropriate when we have two sources of information **about the same individuals** that is **linked by a common column**.\n",
    "- The common column is called the **join key**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these two cells to set up the next example.\n",
    "\n",
    "temps = pd.DataFrame({\n",
    "    'City': ['San Diego', 'Toronto', 'Rome'],\n",
    "    'Temperature': [76, 28, 56]\n",
    "})\n",
    "\n",
    "countries = pd.DataFrame({\n",
    "    'City': ['Toronto', 'Shanghai', 'San Diego'],\n",
    "    'Country': ['Canada', 'China', 'USA']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75660ef2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext pandas_tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da998a61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's work with a small example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd97a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e84e65",
   "metadata": {},
   "source": [
    "We'd like to combine both DataFrames, but it's not immediately clear if `pd.concat` would be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d996f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It turns out that the right tool to use is the `merge` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc832c21",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%pt\n",
    "\n",
    "temps.merge(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c4eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `merge` method\n",
    "\n",
    "- The `merge` DataFrame method joins two tables by columns or indexes.\n",
    "    - \"Merge\" is just `pandas`' word for \"join\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e39242",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When using the `merge` method, the DataFrame before `.merge` is the \"left\" DataFrame, and the DataFrame passed into `.merge` is the \"right\" DataFrame.\n",
    "    - In `temps.merge(countries)`, `temps` is considered the \"left\" DataFrame and `countries` is the \"right\" DataFrame; the columns from the left DataFrame appear to the left of the columns from right DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d83de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- By default:\n",
    "    - If join keys are not specified, all shared columns between the two DataFrames are used.\n",
    "    - The \"type\" of join performed is an inner join."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac2b87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Join types: inner joins\n",
    "\n",
    "- Note that `'Rome'` and `'Shanghai'` do not appear in the merged DataFrame.\n",
    "- This is because there is:\n",
    "    - no city named `'Rome'` in the right DataFrame, and\n",
    "    - no city named `'Shanghai'` in the left DataFrame.\n",
    "- The default type of join that `merge` performs is an **inner join**, which keeps the **intersection** of the join keys.\n",
    "\n",
    "\n",
    "<center><img src='imgs/image_0.png' width=20%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f811b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different join types\n",
    "\n",
    "We can change the type of join performed by changing the `how` argument in `merge`. Let's experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77526cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default value of how is 'inner'.\n",
    "temps.merge(countries, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the NaNs!\n",
    "temps.merge(countries, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1b014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temps.merge(countries, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pt\n",
    "\n",
    "temps.merge(countries, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9476e",
   "metadata": {},
   "source": [
    "Note that an outer join is what `pd.concat` performs by default, when there are no duplicated keys in either DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44278bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([temps.set_index('City'), countries.set_index('City')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac15f23",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different join types handle mismatches differently\n",
    "\n",
    "There are four types of joins.\n",
    "\n",
    "* **Inner:** keep **only** matching keys (intersection).\n",
    "* **Outer:** keeps **all** keys in both DataFrames (union).\n",
    "* **Left:** keep all keys in the left DataFrame, whether or not they are in the right DataFrame.\n",
    "* **Right:** keep all keys in the right DataFrame, whether or not they are in the left DataFrame.\n",
    "\n",
    "<center><img src='imgs/image_1.png' width=30%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ca518",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Symmetry\n",
    "\n",
    "Note that `a.merge(b, how='left')` contains the same information as `b.merge(a, how='right')`, just in a different order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9889cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps.merge(countries, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f436c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.merge(temps, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af032a3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specifying join keys\n",
    "\n",
    "- `pandas` defaults to using all shared column names as join keys.\n",
    "- If there are multiple shared column names and you only want to join on one of them, **or** if there are no shared column names, then you will need to specify which columns to join on.\n",
    "- Two solutions:\n",
    "    1.  Use the `on` argument if the desired columns have the same names in both DataFrames.\n",
    "    2. Use the `left_on` or `left_index` argument AND the `right_on` or `right_index` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aec0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd204e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bf9fa",
   "metadata": {},
   "source": [
    "This is not what we're looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e7808",
   "metadata": {},
   "source": [
    "Instead, we need to tell `pandas` to look in the `'Name'` column of `exams` and `'Student'` column of `overall`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d657c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall, left_on='Name', right_on='Student')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc8995",
   "metadata": {},
   "source": [
    "If there are shared column names in the two DataFrames you are merging **that you are not using as join keys**, `'_x'` and `'_y'` are appended to their names by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db021eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exams.merge(overall, left_on='Name', right_on='Student', suffixes=('_Exam', '_Overall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9059bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Many-to-one & many-to-many joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7eae26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-to-one joins\n",
    "\n",
    "- So far in this lecture, the joins we have worked with are called **one-to-one** joins.\n",
    "- Neither the left DataFrame nor the right DataFrame contained any duplicates in the join key.\n",
    "- What if there are duplicated join keys, in one or both of the DataFrames we are merging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5378a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the next example.\n",
    "\n",
    "profs = pd.DataFrame(\n",
    "[['Brad', 'UCB', 9],\n",
    " ['Janine', 'UCSD', 8],\n",
    " ['Marina', 'UIC', 7],\n",
    " ['Justin', 'OSU', 5],\n",
    " ['Soohyun', 'UCSD', 2],\n",
    " ['Suraj', 'UCB', 2]],\n",
    "    columns=['Name', 'School', 'Years']\n",
    ")\n",
    "\n",
    "schools = pd.DataFrame({\n",
    "    'Abr': ['UCSD', 'UCLA', 'UCB', 'UIC'],\n",
    "    'Full': ['University of California, San Diego', 'University of California, Los Angeles', 'University of California, Berkeley', 'University of Illinois Chicago']\n",
    "})\n",
    "\n",
    "programs = pd.DataFrame({\n",
    "    'uni': ['UCSD', 'UCSD', 'UCSD', 'UCB', 'OSU', 'OSU'],\n",
    "    'dept': ['Math', 'HDSI', 'COGS', 'CS', 'Math', 'CS'],\n",
    "    'grad_students': [205, 54, 281, 439, 304, 193]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4801c5d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-one joins\n",
    "\n",
    "- Many-to-one joins are joins where **one** of the DataFrames contains duplicate values in the join key. \n",
    "- The resulting DataFrame will preserve those duplicate entries as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492a7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "schools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac6107",
   "metadata": {},
   "source": [
    "Note that when merging `profs` and `schools`, the information from `schools` is duplicated.\n",
    "- `'University of California, San Diego'` appears twice.\n",
    "- `'University of California, Berkeley'` appears three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a18661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is a left merge most appropriate here?\n",
    "profs.merge(schools, left_on='School', right_on='Abr', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c7090",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-many joins\n",
    "\n",
    "Many-to-many joins are joins where both DataFrames have duplicate values in the join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ec97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd14679",
   "metadata": {},
   "source": [
    "Before running the following cell, try predicting the number of rows in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pt\n",
    "\n",
    "profs.merge(programs, left_on='School', right_on='uni')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6525c8",
   "metadata": {},
   "source": [
    "- `merge` stitched together every UCSD row in `profs` with every UCSD row in `programs`. \n",
    "- Since there were 2 UCSD rows in `profs` and 3 in `programs`, there are $2 \\cdot 3 = 6$ UCSD rows in the output. The same applies for all other schools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a37e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393b3ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Timestamps in `pandas` are stored using `pd.Timestamp` and `pd.Timedelta` objects.\n",
    "- `pd.concat` \"stitches\" two or more DataFrames together, either vertically or horizontally.\n",
    "    - Vertically: looks at column names. Horizontally: looks at row indexes.\n",
    "- The `merge` DataFrame method **joins** two DataFrames together based on a shared column, called a join key. There are four types of joins:\n",
    "    - Inner join: keeps the **intersection** of the join keys.\n",
    "    - Outer join: keeps the **union** of the join keys.\n",
    "    - Left/right joins: keeps all of the join keys in the left/right DataFrame.\n",
    "    - In outer/left/right joins, all missing fields are filled with `NaN`s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1561851",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "Cleaning messy, real-world data."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
