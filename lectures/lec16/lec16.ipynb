{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import bs4\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 16 ‚Äì More Parsing Examples\n",
    "\n",
    "## DSC 80, Winter 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dadf287",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üì£ Announcements\n",
    "- Lab 6 (web scraping and APIs) is due on **Wednesday, February 22nd at 4:00PM (no slip days!).**\n",
    "    - No slip days are allowed because we will take up the solutions in Discussion 6 at 5:00PM on Wednesday.\n",
    "- Project 3 is due **Thursday, February 23rd at 11:59PM**. Read about it at [dsc80.com/project3](https://dsc80.com/project3).\n",
    "    - Try to finish Part 1 over the long weekend.\n",
    "- Midterm Exam scores are released, and regrades are due on **Wednesday, February 22nd at 11:59PM**.\n",
    "    - Remember that it's only worth 10%, and that we have a redemption policy.\n",
    "- The [tutor application](https://academicaffairs.ucsd.edu/Modules/ASES/Apply.aspx?cid=5010) is due on **Sunday, February 19th at 11:59PM** ‚Äì consider applying!\n",
    "- Take a look at the updated [office hours schedule](https://dsc80.com/calendar) for next week.\n",
    "    - No lecture or in-person OH on Monday (but some remote OH)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Parsing HTML using Beautiful Soup.\n",
    "    - Example: Scraping the HDSI Faculty page.\n",
    "    - Example: Scraping quotes.\n",
    "- Nested vs. flat data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a797498",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parsing HTML using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7a4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `BeautifulSoup` objects\n",
    "\n",
    "- `bs4.BeautifulSoup` takes in a string or file-like object representing HTML (markup) and returns a **parsed** document.\n",
    "- Remember, HTML documents are represented as **trees**, under the \"Document Object Model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = '''\n",
    "<html>\n",
    "    <body>\n",
    "      <div id=\"content\">\n",
    "        <h1>Heading here</h1>\n",
    "        <p>My First paragraph</p>\n",
    "        <p>My <em>second</em> paragraph</p>\n",
    "        <hr>\n",
    "      </div>\n",
    "      <div id=\"nav\">\n",
    "        <ul>\n",
    "          <li>item 1</li>\n",
    "          <li>item 2</li>\n",
    "          <li>item 3</li>\n",
    "        </ul>\n",
    "      </div>\n",
    "    </body>\n",
    "</html>\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a21d52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding elements in a tree\n",
    "\n",
    "The most common methods you'll use to find _tags_ in a `soup` object are:\n",
    "- `soup.find(tag)`, which finds the **first** instance of a tag (the first one on the page, i.e. the first one that DFS sees).\n",
    "    - More general: `soup.find(name=None, attrs={}, recursive=True, text=None, **kwargs)`.\n",
    "- `soup.find_all(tag)`, which finds **all** instances of a tag.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ce4de4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `find_all`\n",
    "\n",
    "`find_all` returns a list of all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3fb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.text for x in soup.find_all('li')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e94fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Node attributes\n",
    "* The `text` attribute of a tag element gets the text between the opening and closing tags.\n",
    "* The `attrs` attribute lists all attributes of a tag.\n",
    "* The `get(key)` method gets the value of a tag attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a308ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1919b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div').get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f874f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `get` method must be called directly on the node that contains the attribute you're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While there are multiple 'id' attributes, none of them are in the <html> tag at the top.\n",
    "soup.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4116d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find('div').get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01292e8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Scraping the HDSI Faculty page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfdb9a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Let's try and extract a list of HDSI Faculty from https://datascience.ucsd.edu/about/faculty/faculty/.\n",
    "\n",
    "A good first step is to use the \"inspect element\" tool in our web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb436506",
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_response = requests.get('https://datascience.ucsd.edu/about/faculty/faculty/')\n",
    "fac_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(fac_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c3c4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It seems like the relevant `<div>`s for faculty are the ones where the `data-entry-type` attribute is equal to `'individual'`. Let's find all of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69823e8c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', attrs={'data-entry-type': 'individual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d11b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afe6f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Within here, we need to extract each faculty member's name. It seems like names are stored in the `title` attribute within an `<a>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc529f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('a').get('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca40939",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also extract job titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac50856",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('h4').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17c9ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And bios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('div', attrs={'class': 'cn-bio'}).text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2638aa93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's create a DataFrame consisting of names and bios for each faculty member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bd6cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = [div.find('a').get('title') for div in divs]\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for div in divs:\n",
    "    h4 = div.find('h4')\n",
    "    if h4:\n",
    "        titles.append(h4.text)\n",
    "    else:\n",
    "        titles.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5138d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = []\n",
    "for div in divs:\n",
    "    bio_div = div.find('div', attrs={'class': 'cn-bio'})\n",
    "    if bio_div:\n",
    "        bios.append(bio_div.text.strip())\n",
    "    else:\n",
    "        bios.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c7ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty = pd.DataFrame().assign(name=names, title=titles, bio=bios)\n",
    "faculty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d5f399",
   "metadata": {},
   "source": [
    "Now we have a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf508d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty[faculty['title'] == 'Lecturer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c7ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we want to get faculty members' pictures? It seems like we should look at the attributes of an `<img>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6791f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_picture(name):\n",
    "    idx = names.index(name)\n",
    "    url = divs[idx].find('img').get('srcset')\n",
    "    url = url.replace('https://sp-ao.shortpixel.ai/client/to_webp,q_lossless,ret_img/', '') \\\n",
    "             .replace(' 1x', '')\n",
    "    display(Image(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_picture('Suraj Rampure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d4415",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Scraping quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f606c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Scraping quotes\n",
    "\n",
    "Let's scrape quotes from https://quotes.toscrape.com/.\n",
    "\n",
    "<center><img src=\"imgs/quotes2scrape.png\" width=60%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb141b04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Specifically, let's try to make a DataFrame that looks like the one below:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>quote</th>\n",
    "      <th>author</th>\n",
    "      <th>author_url</th>\n",
    "      <th>tags</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>‚ÄúThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.‚Äù</td>\n",
    "      <td>Albert Einstein</td>\n",
    "      <td>https://quotes.toscrape.com/author/Albert-Einstein</td>\n",
    "      <td>change,deep-thoughts,thinking,world</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>‚ÄúIt is our choices, Harry, that show what we truly are, far more than our abilities.‚Äù</td>\n",
    "      <td>J.K. Rowling</td>\n",
    "      <td>https://quotes.toscrape.com/author/J-K-Rowling</td>\n",
    "      <td>abilities,choices</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>‚ÄúThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.‚Äù</td>\n",
    "      <td>Albert Einstein</td>\n",
    "      <td>https://quotes.toscrape.com/author/Albert-Einstein</td>\n",
    "      <td>inspirational,life,live,miracle,miracles</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e66358",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The plan\n",
    "\n",
    "Eventually, we will create a single function ‚Äì `quote_df` ‚Äì which takes in an integer `n` and returns a **DataFrame** with the quotes on the **first `n` pages** of https://quotes.toscrape.com/.\n",
    "\n",
    "To do this, we will define several helper functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13e070",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `download_page(i)`, which downloads a **single page** (page `i`) and returns a `BeautifulSoup` object of the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345f5d6e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `process_quote(div)`, which takes in a `<div>` tree corresponding to a **single quote** and returns a Series containing all of the relevant information for that quote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4fa97",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `process_page(divs)`, which takes in a list of `<div>` trees corresponding to a **single page** and returns a DataFrame containing all of the relevant information for all quotes on that page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66214488",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key principle: some of our helper functions will make **requests**, and others will **parse**, but none will do both! \n",
    "- Easier to debug and catch errors.\n",
    "- Avoids unnecessary requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a4563",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Downloading a single page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db125af",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def download_page(i):\n",
    "    url = f'https://quotes.toscrape.com/page/{i}'\n",
    "    request = requests.get(url)\n",
    "    return bs4.BeautifulSoup(request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452bb34",
   "metadata": {},
   "source": [
    "In `quote_df`, we will call `download_page` repeatedly ‚Äì once for `i=1`, once for `i=2`, ..., `i = n`. For now, we will work with just page 5 (chosen arbitrarily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = download_page(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59697cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parsing a single page\n",
    "\n",
    "Let's look at the page's source code (via \"inspect element\") to find where the quotes in the page are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67152459",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = soup.find_all('div', attrs={'class': 'quote'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6757bf4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From this `<div>`, we can extract the quote, author name, author's URL, and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('span', attrs={'class': 'text'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1272c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('small', attrs={'class': 'author'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aafc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[0].find('meta', attrs={'class': 'keywords'}).get('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497f2fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's implement our next function, `process_quote`, which takes in a `<div>` corresponding to a single quote and returns a **Series** containing the quote's information.\n",
    "\n",
    "Note that this approach is different than the approach taken in the HDSI Faculty page example ‚Äì there, we created each column of our final DataFrame separately, while here we are creating one **row** of our final DataFrame at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_quote(div):\n",
    "    quote = div.find('span', attrs={'class': 'text'}).text\n",
    "    author = div.find('small', attrs={'class': 'author'}).text\n",
    "    author_url = 'https://quotes.toscrape.com' + div.find('a').get('href')\n",
    "    tags = div.find('meta', attrs={'class': 'keywords'}).get('content')\n",
    "    \n",
    "    return pd.Series({'quote': quote, 'author': author, 'author_url': author_url, 'tags': tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b620164",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_quote(divs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a761e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our last helper function will take in a **list** of `<div>`s, call `process_quote` on each `<div>` in the list, and return a **DataFrame**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(divs):\n",
    "    return pd.DataFrame([process_quote(div) for div in divs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_page(divs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0408fbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f71cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_df(n):\n",
    "    '''Returns a DataFrame containing the quotes on the first n pages of https://quotes.toscrape.com/.'''\n",
    "    dfs = []\n",
    "    for i in range(1, n + 1):\n",
    "        # Download page n and create a BeautifulSoup object.\n",
    "        soup = download_page(i)\n",
    "        \n",
    "        # Create DataFrame using the information in that page.\n",
    "        divs = soup.find_all('div', attrs={'class': 'quote'})\n",
    "        df = process_page(divs)\n",
    "        \n",
    "        # Append DataFrame to dfs.\n",
    "        dfs.append(df)\n",
    "        \n",
    "    # Stitch all DataFrames together.\n",
    "    return pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a410385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_three_pages = quote_df(3)\n",
    "first_three_pages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64de1c",
   "metadata": {},
   "source": [
    "The elements in the `'tags'` column are all strings, but they look like lists. This is not ideal, as we will see shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f46b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Key takeaways\n",
    "\n",
    "* Make as few requests as possible.\n",
    "* Create a request and parsing plan **beforehand**.\n",
    "* Create your output schema **beforehand**.\n",
    "* Make requests and parse in **separate functions**!\n",
    "* See Lab 6, Question 2 for a related example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976a583",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested vs. flat data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0ba3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nested vs. flat data formats\n",
    "\n",
    "- **Nested** data formats, like HTML, JSON, and XML, allow us to represent hierarchical relationships between variables.\n",
    "\n",
    "* **Flat** (i.e. tabular) data formats, like CSV, do not.\n",
    "\n",
    "<center><img src=\"imgs/hierarchy.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56eb463",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: JSON Crack\n",
    "\n",
    "The site [jsoncrack.com](https://jsoncrack.com/editor) allows you to upload a JSON file and visualizes it. Let's try it with `data/family.json`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90c5f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Scraping quotes, again\n",
    "\n",
    "- Suppose we obtained the quotes data via an API and saved it to the file `data/quotes2scrape.json`.\n",
    "- `quotes2scrape.json` is a **JSON records** file; each line is a valid JSON object, **but the entire document is not**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join('data', 'quotes2scrape.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1638d5dc",
   "metadata": {},
   "source": [
    "Note that for a single quote, we have keys for `'auth_url'`, `'quote_auth'`, `'quote_text'`, `'bio'`, `'dob'`, and `'tags'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ae99c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since each line is a separate JSON object, let's read in each line one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e703ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [json.loads(x) for x in open(os.path.join('data', 'quotes2scrape.json'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d17e8a",
   "metadata": {},
   "source": [
    "Let's convert the result to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(L)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837a6d6",
   "metadata": {},
   "source": [
    "What data type is the `'tags'` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1558e39",
   "metadata": {},
   "source": [
    "Let's save `df` to a CSV and read it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_again = pd.read_csv('out.csv')\n",
    "df_again.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d4795f",
   "metadata": {},
   "source": [
    "What data type is the `'tags'` column now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45cc5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_again['tags'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5b1e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bae91f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So that we don't have to deal with lists within Series, we can **flatten** lists of tags so that there is **one column per unique tag**.\n",
    "    - For example, consider the tag `'inspirational'`.\n",
    "    - If a quote has a 1 in the `'inspirational'` column, it **was** tagged `'inspirational'`.\n",
    "    - If a quote has a 0 in the `'inspirational'` column, it **was not** tagged `'inspirational'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520566d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This process ‚Äì of converting categorical variables into columns of 1s and 0s ‚Äì is called **one-hot encoding**. We will revisit it in a few weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7d350",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's write a function that takes in the list of tags (`taglist`) for a given quote and returns the one-hot-encoded sequence of 1s and 0s for that quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tags(taglist):\n",
    "    return pd.Series({k:1 for k in taglist}, dtype=float)\n",
    "\n",
    "tags = df['tags'].apply(flatten_tags).fillna(0).astype(int)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ed85d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's combine this one-hot-encoded DataFrame with `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([df, tags], axis=1).drop(columns='tags')\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f1f55",
   "metadata": {},
   "source": [
    "If we want all quotes tagged `'inspiration'`, we can simply query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[df_full['inspirational'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a7206",
   "metadata": {},
   "source": [
    "Note that this DataFrame representation of the response JSON takes up much more space than the original JSON. Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269efd96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ab7da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Beautiful Soup is an HTML parser that allows us to (somewhat) easily extract information from HTML documents.\n",
    "    - `soup.find` and `soup.find_all` are the functions you will use most often.\n",
    "- When writing scraping code:\n",
    "    - Use \"inspect element\" to identify the names of tags and attributes that are relevant to the information you want to extract.\n",
    "    - Separate your logic for making requests and for parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c64f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "All about regular expressions!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
